import numpy as np
from langchain.vectorstores import FAISS
from langchain.schema import Document
from typing import Any
import re

from .embedded import *

class Retrieve:
    company_metadata = {
        "4â„ƒ": ["4â„ƒ", "ãƒ¨ãƒ³ãƒ‰ã‚·ãƒ¼", "ãƒ¨ãƒ³ãƒ‰ã‚·ãƒ¼ã‚¸ãƒ¥ã‚¨ãƒªãƒ¼"],
        "IHI": ["IHI", "çŸ³å·å³¶æ’­ç£¨", "çŸ³å·å³¶æ’­ç£¨é‡å·¥æ¥­"],
        "NISSAN": ["NISSAN", "æ—¥ç”£", "æ—¥ç”£è‡ªå‹•è»Š"],
        "KAGOME": ["KAGOME", "ã‚«ã‚´ãƒ¡"],
        "KITZ": ["KITZ", "ã‚­ãƒƒãƒ„"],
        "KUREHA": ["KUREHA", "ã‚¯ãƒ¬ãƒ", "æ ªå¼ä¼šç¤¾ã‚¯ãƒ¬ãƒ"],
        "GLORY": ["GLORY", "ã‚°ãƒ­ãƒªãƒ¼", "ã‚°ãƒ­ãƒ¼ãƒªãƒ¼"],
        "ã‚µãƒ³ãƒˆãƒªãƒ¼": ["ã‚µãƒ³ãƒˆãƒªãƒ¼", "Suntory"],
        "ãƒã‚¦ã‚¹é£Ÿå“": ["ãƒã‚¦ã‚¹é£Ÿå“", "House Foods"],
        "ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯": ["ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯", "Panasonic", "ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ã‚°ãƒ«ãƒ¼ãƒ—"],
        "Media Do": ["Media Do", "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‰ã‚¥"],
        "MOS": ["MOS", "ãƒ¢ã‚¹ãƒ•ãƒ¼ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹", "ãƒ¢ã‚¹ãƒãƒ¼ã‚¬ãƒ¼", "ãƒ¢ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—"],
        "ãƒ©ã‚¤ãƒ•ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³": ["ãƒ©ã‚¤ãƒ•ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ©ã‚¤ãƒ•"],
        "é«˜æ¾ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³": ["é«˜æ¾ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³", "é«˜æ¾å»ºè¨­"],
        "å…¨å›½ä¿è¨¼æ ªå¼ä¼šç¤¾": ["å…¨å›½ä¿è¨¼æ ªå¼ä¼šç¤¾", "å…¨å›½ä¿è¨¼"],
        "æ±æ€¥ä¸å‹•ç”£": ["æ±æ€¥ä¸å‹•ç”£", "Tokyu Real Estate", "Tokyu"],
        "TOYO": ["TOYO", "æ±æ´‹ã‚´ãƒ ", "TOYO TIRES", "æ±æ´‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"],
        "æ—¥æ¸…é£Ÿå“": ["æ—¥æ¸…é£Ÿå“", "Nissin", "Nissin Foods"],
        "meiji": ["meiji", "æ˜æ²»", "æ˜æ²»è£½è“", "Meiji Seika"]
    }

    def __init__(self, embeddings: Embeddings, faiss_index_path: str) -> None:
        print("start Retrieve")
        self.embeddings = embeddings
        self.vectorstore = FAISS.load_local(
            folder_path=faiss_index_path,
            embeddings=self.embeddings,
            allow_dangerous_deserialization=True
        )
        self.validate_index()

    def validate_index(self):
        """FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        index_size = self.vectorstore.index.ntotal
        docstore_size = len(self.vectorstore.index_to_docstore_id)

        if index_size != docstore_size:
            print(f"[è­¦å‘Š] FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ `index_to_docstore_id` ã®ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
            print(f"FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º: {index_size}")
            print(f"index_to_docstore_id ã®ã‚µã‚¤ã‚º: {docstore_size}")

    def extract_company_name(self, query: str) -> str:
        """è³ªå•ã‹ã‚‰ä¼æ¥­åã‚’æŠ½å‡ºã™ã‚‹"""
        for company, aliases in self.company_metadata.items():
            for alias in aliases:
                # ğŸ”¹ `\b` ã‚’å‰Šé™¤ã—ã€éƒ¨åˆ†ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
                if re.search(re.escape(alias), query, re.IGNORECASE):
                    return company  # ä¸€è‡´ã—ãŸä¼æ¥­åã‚’è¿”ã™
        return None

    # def search(self, query: str, top_k: int = 5) -> list[Document]:
    #     """ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é¡ä¼¼æ¤œç´¢"""
    #     return self.vectorstore.similarity_search(query, k=top_k)

    def old_search(self, query: str, top_k: int = 5, return_text: bool = True) -> list[Document] | str:
        """ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é¡ä¼¼æ¤œç´¢ã‚’è¡Œã†
    
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
            top_k (int, optional): å–å¾—ã™ã‚‹é¡ä¼¼æ–‡æ›¸ã®æœ€å¤§æ•°. Defaults to 5.
            return_text (bool, optional): Trueã®å ´åˆã€æ¤œç´¢çµæœã‚’çµåˆã—ãŸæ–‡å­—åˆ—ã§è¿”ã™. Defaults to False.

        Returns:
            Union[list[Document], str]: return_text=True ã®å ´åˆã¯æ–‡å­—åˆ—ã€False ã®å ´åˆã¯ Document ã®ãƒªã‚¹ãƒˆ
        """
        query_embedding = self.embeddings.embed_query(query)
        relevant_docs = self.vectorstore.similarity_search_by_vector(
            np.array(query_embedding, dtype=np.float32), k=top_k
        )
        if return_text:
            return "\n\n".join([doc.page_content for doc in relevant_docs])
        return relevant_docs
    
    def search(self, query: str, top_k: int = 5, fetch_k: int = 20, return_text: bool = True) -> list[Document] | str:
        """ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é¡ä¼¼æ¤œç´¢ã‚’è¡Œã†
        - è³ªå•ã«ä¼æ¥­åãŒã‚ã‚‹å ´åˆã«ã€ä»˜å±ã—ã¦ã„ã‚‹ãƒ¡ã‚¿æƒ…å ±ã®ä¼æ¥­åã¨ä¸€è‡´ã—ã¦ã„ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        ã—ãŸä¸Šã§ã€é¡ä¼¼åº¦æ¤œç´¢ã‚’è¡Œã†ã€‚
    
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
            top_k (int, optional): å–å¾—ã™ã‚‹é¡ä¼¼æ–‡æ›¸ã®æœ€å¤§æ•°. Defaults to 5.
            return_text (bool, optional): Trueã®å ´åˆã€æ¤œç´¢çµæœã‚’çµåˆã—ãŸæ–‡å­—åˆ—ã§è¿”ã™. Defaults to False.

        Returns:
            Union[list[Document], str]: return_text=True ã®å ´åˆã¯æ–‡å­—åˆ—ã€False ã®å ´åˆã¯ Document ã®ãƒªã‚¹ãƒˆ
        """
        # ** ä¼æ¥­åã®æŠ½å‡º **
        company_name = self.extract_company_name(query)

        query_embedding = self.embeddings.embed_query(query)

        if company_name:
            print("")
            print(f"ä¼æ¥­å '{company_name}' ã‚’æ¤œå‡ºã€‚å¯¾è±¡ä¼æ¥­ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

            # ä¼æ¥­åã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨
            relevant_docs = self.vectorstore.similarity_search_by_vector(
                np.array(query_embedding, dtype=np.float32), 
                k=top_k, 
                filter={"company": company_name},  # ä¼æ¥­åã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                fetch_k=fetch_k
            )
            print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(relevant_docs)} ä»¶")
            print("")
        else:
            print("")
            print("ä¼æ¥­åãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ¤œç´¢ã—ã¾ã™ã€‚")
            print("")
            relevant_docs = self.vectorstore.similarity_search_by_vector(
                np.array(query_embedding, dtype=np.float32), k=top_k
            )
    
        if return_text:
            return "\n\n".join([doc.page_content for doc in relevant_docs])
        return relevant_docs
